{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DreRnc/ExplainingExplanations/blob/torch/Explanations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H972d7y9V7J"
      },
      "source": [
        "Dataset : **E-SNLI**. \\\n",
        "Model : **Small T5**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cpKHbnzGEWLt",
        "outputId": "4e2e9cd2-5129-4a21-b1e6-fe30647eb165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ExplainingExplanations'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 59 (delta 19), reused 40 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (59/59), 13.46 MiB | 11.62 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/ExplainingExplanations/ExplainingExplanations\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.35.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 1)) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DreRnc/ExplainingExplanations.git\n",
        "%cd ExplainingExplanations\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYNhbZhXEWLu"
      },
      "source": [
        "# 1.0 Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZvGBSfFEWLv"
      },
      "source": [
        "## 1.1 Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0kOOUYl19UHq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"esnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zugxo8WgEWLw",
        "outputId": "dddf92d4-3262-405d-f03c-7f3a5466fa31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training_set:  (549367, 6)\n",
            "Shae of validation_set:  (9842, 6)\n",
            "Shape of test_set:  (9824, 6)\n"
          ]
        }
      ],
      "source": [
        "training_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]\n",
        "test_set = dataset[\"test\"]\n",
        "\n",
        "print(\"Shape of training_set: \", training_set.shape)\n",
        "print(\"Shae of validation_set: \", validation_set.shape)\n",
        "print(\"Shape of test_set: \", test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kaX3QbEWLw",
        "outputId": "efbf320d-1f23-42c4-eec9-47538a124c77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': 'A person on a horse jumps over a broken down airplane.',\n",
              " 'hypothesis': 'A person is training his horse for a competition.',\n",
              " 'label': 1,\n",
              " 'explanation_1': 'the person is not necessarily training his horse',\n",
              " 'explanation_2': '',\n",
              " 'explanation_3': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "training_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLgS-BVbEWLx",
        "outputId": "7bf1a5f3-d513-4f69-fe7c-86bdcee5932d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_small:  (5000, 6)\n",
            "Shape of valid_small:  (5000, 6)\n",
            "Shape of test_small:  (5000, 6)\n"
          ]
        }
      ],
      "source": [
        "n_train = n_valid = n_test = 5000\n",
        "\n",
        "train_small = training_set.select(range(n_train))\n",
        "valid_small = validation_set.select(range(n_valid))\n",
        "test_small = test_set.select(range(n_test))\n",
        "\n",
        "print(\"Shape of train_small: \", train_small.shape)\n",
        "print(\"Shape of valid_small: \", valid_small.shape)\n",
        "print(\"Shape of test_small: \", test_small.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFt0woXsEWLx"
      },
      "source": [
        "## 1.2 Loading T5 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyczhxOR-jwU",
        "outputId": "2037d920-557e-4323-d491-32240ec8d274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1nc40MHGQQx"
      },
      "source": [
        "Test **zero-shot** on a random task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKG-so0--7ug",
        "outputId": "34391740-8351-4a3c-e74f-d15e2771c0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour Dre, je pense que la version anglaise est bonne pour nous.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer(\n",
        "    \"translate English to French: Hello Dre, I think the English version is ok for us.\",\n",
        "    return_tensors=\"pt\",\n",
        ").input_ids\n",
        "outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True, max_length=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxesGnaFEWLz"
      },
      "source": [
        "## 1.3 Zero-shot example to Verify Everything is Working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oVqJLHXJEWLz"
      },
      "outputs": [],
      "source": [
        "from src.utils import generate_prompt_mnli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZILJcgoDO9b",
        "outputId": "537fb2d2-34d2-479d-d761-6d7b3ae856ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': 'A person on a horse jumps over a broken down airplane.',\n",
              " 'hypothesis': 'A person is training his horse for a competition.',\n",
              " 'label': 1,\n",
              " 'explanation_1': 'the person is not necessarily training his horse',\n",
              " 'explanation_2': '',\n",
              " 'explanation_3': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "example = training_set[0]\n",
        "example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezSzRF_PEWLz"
      },
      "source": [
        "Generating the prompt:\n",
        "\n",
        "<b><u> mnli hypothesis: </b></u> The St. Louis Cardinals have always won. <b><u> premise: </b></u> yeah well losing is i mean i’m i’m originally from Saint Louis and Saint Louis Cardinals when they were there were uh a mostly a losing team but\n",
        "\n",
        "Output:\n",
        "* 0: Entailment\n",
        "* 1: Neutral\n",
        "* 2: Contradiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7D2MQG6qJYnI",
        "outputId": "daa5b5fa-502b-4f27-d1b0-89aa7d77ebd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mnli hypothesis: A person is training his horse for a competition. premise: A person on a horse jumps over a broken down airplane.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "prompt = generate_prompt_mnli(example)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1roa6HcIi3e",
        "outputId": "e5bf0477-f40e-47ba-8c12-dd2a6bcf9ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQvhd35vEWL1"
      },
      "source": [
        "## 1.4  Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfF032XGEWL1",
        "outputId": "a070c406-29fb-4d66-b970-632c0c9d6fe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetInfo(description='', citation='', homepage='', license='', features={'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None), 'explanation_1': Value(dtype='string', id=None), 'explanation_2': Value(dtype='string', id=None), 'explanation_3': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='parquet', dataset_name='esnli', config_name='plain_text', version=0.0.2, splits={'train': SplitInfo(name='train', num_bytes=107611996, num_examples=549367, shard_lengths=None, dataset_name='esnli'), 'validation': SplitInfo(name='validation', num_bytes=3416319, num_examples=9842, shard_lengths=None, dataset_name='esnli'), 'test': SplitInfo(name='test', num_bytes=3379781, num_examples=9824, shard_lengths=None, dataset_name='esnli')}, download_checksums={'hf://datasets/esnli@f01d1430c0ad65a3785d06079a0e01e015e769b8/plain_text/train/0000.parquet': {'num_bytes': 39334649, 'checksum': None}, 'hf://datasets/esnli@f01d1430c0ad65a3785d06079a0e01e015e769b8/plain_text/validation/0000.parquet': {'num_bytes': 1623679, 'checksum': None}, 'hf://datasets/esnli@f01d1430c0ad65a3785d06079a0e01e015e769b8/plain_text/test/0000.parquet': {'num_bytes': 1607507, 'checksum': None}}, download_size=42565835, post_processing_size=None, dataset_size=114408096, size_in_bytes=156973931)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_small.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYweTWpKEWL1",
        "outputId": "b073b45e-47a0-4a69-f74f-6743a17cc8bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': 'A person on a horse jumps over a broken down airplane.',\n",
              " 'hypothesis': 'A person is training his horse for a competition.',\n",
              " 'label': 1,\n",
              " 'explanation_1': 'the person is not necessarily training his horse',\n",
              " 'explanation_2': '',\n",
              " 'explanation_3': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "train_small[0][\"prompt\"] = \"hello\"\n",
        "\n",
        "train_small[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6EukG0TEWL1",
        "outputId": "819f2410-22f5-447e-9657-43f91b7503ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': Value(dtype='string', id=None),\n",
              " 'hypothesis': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              " 'explanation_1': Value(dtype='string', id=None),\n",
              " 'explanation_2': Value(dtype='string', id=None),\n",
              " 'explanation_3': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "train_small.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HbuROCKBEWL2"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from src.utils import tokenize_function\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IlQmLxMtEWL2"
      },
      "outputs": [],
      "source": [
        "tokenize_mapping = partial(tokenize_function, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRqHwqpOEWL3",
        "outputId": "b9352e7a-1429-4510-d5f6-a9fd2697102e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to tokenize:  0.10033464431762695\n",
            "Shape of train_small_tokenized:  (5000, 9)\n",
            "Shape of valid_small_tokenized:  (5000, 9)\n",
            "Shape of test_small_tokenized:  (5000, 9)\n"
          ]
        }
      ],
      "source": [
        "time_init = time.time()\n",
        "train_small_tokenized = train_small.map(tokenize_mapping, batched=True).with_format(\"torch\")\n",
        "valid_small_tokenized = valid_small.map(tokenize_mapping, batched=True).with_format(\"torch\")\n",
        "test_small_tokenized = test_small.map(tokenize_mapping, batched=True).with_format(\"torch\")\n",
        "time_end = time.time()\n",
        "\n",
        "print(\"Time taken to tokenize: \", time_end - time_init)\n",
        "print(\"Shape of train_small_tokenized: \", train_small_tokenized.shape)\n",
        "print(\"Shape of valid_small_tokenized: \", valid_small_tokenized.shape)\n",
        "print(\"Shape of test_small_tokenized: \", test_small_tokenized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SKgn7mee5Z0B",
        "outputId": "e358316f-bf69-4857-ba1c-f9ace1ab8e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "New column name labels already in the dataset. Please choose a column name which is not already in the dataset. Current columns in the dataset: ['premise', 'hypothesis', 'label', 'explanation_1', 'explanation_2', 'explanation_3', 'input_ids', 'attention_mask', 'labels']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-25d7a40f96f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_small_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_small_tokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_small_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_small_tokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_small_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_small_tokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mrename_column\u001b[0;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             )\n\u001b[1;32m   2204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_column_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2206\u001b[0m                 \u001b[0;34mf\"New column name {new_column_name} already in the dataset. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                 \u001b[0;34mf\"Please choose a column name which is not already in the dataset. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: New column name labels already in the dataset. Please choose a column name which is not already in the dataset. Current columns in the dataset: ['premise', 'hypothesis', 'label', 'explanation_1', 'explanation_2', 'explanation_3', 'input_ids', 'attention_mask', 'labels']"
          ]
        }
      ],
      "source": [
        "train_small_tokenized = train_small_tokenized.rename_column(\"label\", \"labels\")\n",
        "valid_small_tokenized = valid_small_tokenized.rename_column(\"label\", \"labels\")\n",
        "test_small_tokenized = test_small_tokenized.rename_column(\"label\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "h07uqsc25Z0B",
        "outputId": "4141ae96-7a7e-4cd3-ec25-9cddf2394c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': Value(dtype='string', id=None),\n",
              " 'hypothesis': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              " 'explanation_1': Value(dtype='string', id=None),\n",
              " 'explanation_2': Value(dtype='string', id=None),\n",
              " 'explanation_3': Value(dtype='string', id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "train_small_tokenized.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "x3lJR2hU5Z0C"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "19lyOdUl5Z0C"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_small_tokenized, shuffle=True, batch_size=8)\n",
        "eval_dataloader = DataLoader(valid_small_tokenized, batch_size=8)\n",
        "test_dataloader = DataLoader(test_small_tokenized, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4SNHcxuEWL3"
      },
      "source": [
        "# 2.0 Task 1: Zero-shot evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MOwNiKJdEWL3"
      },
      "outputs": [],
      "source": [
        "from src.utils import evaluate_output_mnli\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "7aL8g0625yUD",
        "outputId": "0c639e56-905c-479a-819f-3db8512adc7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fxSLJWA66tpk",
        "outputId": "18b90d12-68d5-44cd-e7ea-7ea3551a9ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/625 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-13a9d4acb4be>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenized_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtokenized_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "seen = 0\n",
        "\n",
        "for tokenized_batch in tqdm(test_dataloader):\n",
        "    tokenized_batch.to(device)\n",
        "    input_ids = tokenized_batch['input_ids']\n",
        "    outputs = model.generate(input_ids)\n",
        "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    correct += evaluate_output_mnli(output, tokenized_batch['labels'])\n",
        "\n",
        "print(\"Accuracy zero shot on test set: \", correct/n_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A5VI8vK6S2p"
      },
      "outputs": [],
      "source": [
        "outputs.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP3N7JCOPd-0"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKIQqziDEWL4"
      },
      "outputs": [],
      "source": [
        "# correct = 0\n",
        "# seen = 0\n",
        "\n",
        "# for datapoint in tqdm(test_small):\n",
        "# prompt = generate_prompt_mnli(datapoint)\n",
        "# input_ids = tokenizer(prompt, return_tensors= \"pt\").input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "# output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "# correct += evaluate_output_mnli(output, datapoint['label'])\n",
        "\n",
        "# print(\"Accuracy zero shot on test set: \", correct/n_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQoQE4naEWL4"
      },
      "source": [
        "# 3.0 Task 2: Fine tuning without explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DSm47RYGNvZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThL1ghEKPVLF"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHxW0vUdGLSa"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\", evaluation_strategy=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4hYJM7lT0Ec"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUa0tn4jGIgS"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_small_tokenized,\n",
        "    eval_dataset=test_small_tokenized,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htxsCXlYTSpF"
      },
      "outputs": [],
      "source": [
        "train_small_tokenized[\"label\"].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_99ruMgTYwq"
      },
      "outputs": [],
      "source": [
        "train_small_tokenized[\"input_ids\"].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HY5nl2RHx5J"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMD_Zq5zEWL4"
      },
      "source": [
        "# 4.0 Task 4: Making the model generate explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnW0W89cEWL4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UZvGBSfFEWLv",
        "FFt0woXsEWLx",
        "RxesGnaFEWLz",
        "DQvhd35vEWL1",
        "s4SNHcxuEWL3",
        "bQoQE4naEWL4",
        "BMD_Zq5zEWL4"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}